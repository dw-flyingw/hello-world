{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748a43fd",
   "metadata": {},
   "source": [
    "vLLM Chat OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01830a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ca8aa",
   "metadata": {},
   "source": [
    "Grab endpoint URL and API key from MLIS, remember to include \"/v1\" for latest version of the OpenAI-compatible API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04213c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
    "openai_api_base = \"/v1\"\n",
    "openai_api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7466dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create OpenAI client interface\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908f993",
   "metadata": {},
   "source": [
    "Interactive chat function with message history. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    # Initialize conversation history\n",
    "    messages = []\n",
    "    \n",
    "    print(\"Chat with \"+model+\"! Type 'quit' to exit.\")\n",
    "    \n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        \n",
    "        # Check for quit command\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Add user message to history\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        try:\n",
    "            # Get model response using chat completion\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages\n",
    "            )\n",
    "            \n",
    "            # Extract assistant's message\n",
    "            assistant_message = response.choices[0].message.content\n",
    "            \n",
    "            # Add assistant's response to history\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "            \n",
    "            # Print the response\n",
    "            print(\"\\nAssistant:\", assistant_message)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da2b69e",
   "metadata": {},
   "source": [
    "Type 'quit' to exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96a31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
